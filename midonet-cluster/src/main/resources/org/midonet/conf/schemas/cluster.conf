// Copyright 2015 Midokura SARL
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MidoNet Cluster configuration schema, containing config for all
// Cluster services.

cluster {
    schemaVersion : 22

    executors {
        max_thread_pool_size: 8
        max_thread_pool_size_description: """ The maximum number of threads
        allocated in the cluster node thread pool.  The cluster node will allocate
        a number of threads in the cluster thread pool equal to the number of
        available processors, but no more than this maximum. """

        thread_pool_shutdown_timeout: 10s
        thread_pool_shutdown_timeout_description: """ The timeout interval for
        shutting down the cluster thread pool."""
        thread_pool_shutdown_timeout_type: "duration"

        thread_pool_name: "cluster-pool"
        thread_pool_name_descriptions: """ The name of the thread pool used
        internally. DO NOT CHANGE."""
    }

    zookeeper {
        use_new_stack : true
    }

    neutron_importer {
        enabled : false
        enabled_description : """ This property defines whether the Neutron
        Importer is active in this Cluster node.  Note that this feature
        is still under active development and is not meant to be used in
        production - KEEP THIS TO FALSE.

        The Neutron Importer is the MidoNet Cluster service in charge of
        importing the virtual network configuration from Neutron DB into the
        MidoNet NSDB.  You can start as many instances of the Neutron Importer
        as you wish.  The instances will elect a leader that will perform all
        import tasks.  If the leader dies, any of the passive instances will take
        over and continue processing the Task queue.
        """

        threads : 1
        threads_description : """ DO NOT CHANGE. """

        delay : 0ms
        delay_description : """ The time that the Importer will wait after
        startup before processing the next task in the Neutron DB. """
        delay_type : "duration"

        period : 1000ms
        period_description : """ The poll interval to query the Neutron DB
        for new import tasks. """
        period_type : "duration"

        connection_string : " "
        connection_string_description : """
        The JDBC connection string to connect to the Neutron DB.  For example:
        jdbc:mysql://192.168.0.1:3306/taskdb
        """

        jdbc_driver_class : "com.mysql.jdbc.Driver"
        jdbc_driver_class_description : """ DO NOT CHANGE. """

        user : " "
        user_description : """ Used in the SQL connection to the Neutron DB."""

        password : " "
        password_description : """
        Used in the SQL connection to the Neutron DB"""
    }

    heartbeat {
        enabled : false
        enabled_description : """ Whether the service is enabled.  The Heartbeat
        service is a simple sanity check that will just log a beat in the log
        files. """

        threads : 1
        threads_description : """ DO NOT CHANGE. """

        delay : 0ms
        delay_description : """ The initial delay until the service
        starts beating. """
        delay_type : "duration"

        period : 1000ms
        period_description : """ The interval between beats. """
        period_type : "duration"
    }

    vxgw {
        enabled : true
        enabled_description : """ The VxLAN Gateway Service performs management
        functions implementing L2 Gateways over VxLAN among MidoNet and physical
        VTEPs.  This service takes care of managing the physical VTEPs
        synchronising state among virtual Networks and the VTEP's OVSDB tables.

        Enable this service if you want this Cluster node to participate in
        VTEP management functions.  You may enable as many Cluster nodes to run
        the VxGW service.  The instances will self-coordinate electing a leader
        that will manage all VTEPs added to MidoNet.  The rest of instances will
        remain passive, and elect a new leader should the first one fail.

        Note that any number of Cluster nodes may have the VxGW service active;
        they will self-coordinate electing a leader that will take over all
        VxLAN management functions, and failover to passive nodes whenever
        necessary.  If you're using the VxLAN Gateway feature, it is recommended
        that you run at least two Cluster nodes with this service active.
        """
    }

    topology_api {
        enabled : false
        enabled_description : """ Whether this Cluster node runs an instance
        of the Topology API service.

        The Topology API is a service that exposes the MidoNet topology via
        RPC, using raw TCP or WebSockets (or both).  The API allows retrieving,
        as well as subscribing to changes in the model subscription to changes.
        You can run as many instances of the Topology API service as you want
        across your deployment.
        """

        socket_enabled : false
        socket_enabled_description : """
        Whether the plain socket interface should be active."""

        port : 8088
        port_description : """
        Port for the plain socket interface."""

        ws_enabled : false
        ws_enabled_description : """
        Whether the websocket interface should be active."""

        ws_port : 8080
        ws_port_description : """
        Port for the websocket interface."""

        ws_path : "/websocket"
        ws_path_description : """
        Path for the websocket url."""

        session_grace_period : 180s
        session_grace_period_description : """
        Time to maintain session subscriptions after an unexpected
        disconnection."""
        session_grace_period_type : "duration"

        session_buffer_size : 16384
        session_buffer_size_description : """
        Maximum number of pending 'on-the-fly' events; it should be at least
        128 and large enough to accomodate the maximum number of devices of
        a certain type. This value also corresponds to the maximum number of
        events that can be maintained during a disconnection."""
    }

    rest_api {
        enabled : true
        enabled_description : """ Whether the API runs in this Cluster
        node.  This service offers a MidoNet REST API.  """

        http_port : 8181
        http_port_description : """ The port on which the REST API will
        be exposed."""

        https_port : 8443
        https_port_description : """ Port on which the HTTPS API should
        be exposed.  Use a value <= 0 to disable https.  Note also that
        the API will expect a keystore to exist in
        /etc/midonet-cluster/ssl/midonet.jks.  For further instructions
        on how to generate the keystore with your certificates please
        refer to the documentation at docs.midonet.org."""

        root_uri: "/midonet-api"
        root_uri_description: """ The root path for all APIs """

        nsdb_lock_timeout : 30s
        nsdb_lock_timeout_description : """ The timeout for acquiring an
        exclusive lock to the NSDB when performing a multi-write operation."""
        nsdb_lock_timeout_type : "duration"
    }

    containers {
        enabled : true
        enabled_description : """Whether the Containers service runs in this
        Cluster node.  This service manages the creation and deletion of service
        containers (such as VPNaaS) across the currently active MidoNet Agent
        nodes."""

        scheduler_timeout : 10s
        scheduler_timeout_description : """Indicates the time interval to wait
        for a scheduled container to be reported running by the host where it
        has been scheduled. If a container is not running when a timeout occurs,
        the selected host will be marked as a bad host and the scheduler will
        attempts to schedule the container on a different host."""

        scheduler_retry : 15s
        scheduler_retry_description : """Indicates the time interval after which
        the scheduler attempts to reschedule a down container."""

        scheduler_max_retries : 10
        scheduler_max_retries_description : """The maximum number of attempts
        the scheduler will retry to schedule a down container. Once this number
        is reached, the scheduler will schedule a new container only as a
        response to an external event, such as the available hosts have changed
        or the operator triggered a manual scheduling."""

        scheduler_bad_host_lifetime : 30s
        scheduler_bad_host_lifetime_description : """Indicates the time interval
        during which a host that previously failed to launch a container is
        marked as bad and being prevented from launching the same container. A
        host is automatically cleared as bad whenever the host status changes."""
    }

    state_proxy {
        enabled : true
        enabled_description : """Whether the State Proxy service runs in this
        Cluster node.  This service provides scalable access to topology state
        table stored in the NSDB."""

        initial_subscriber_queue_size : 16
        initial_subscriber_queue_size_description : """The initial size of a
            subscriber notification queue. Each subscriber is provisioning with
            a queue to provider an order of messages that can accommodate
            asynchronous requests from the subscriber."""

        notify_batch_size : 64
        notify_batch_size_description : """The number of changes that can
            be batched in a single notification."""

        server {
            address : "0.0.0.0"
            address_description : """The listening local IP address"""

            port : 2346
            port_description : """The listening TCP port number."""

            supervisor_threads : 1
            supervisor_threads_description : """The number of threads used to
            accept inbound connections to the State Proxy service."""

            worker_threads : 4
            worker_threads_description : """The number of threads used to
            handle client requests."""

            max_pending_connections : 1024
            max_pending_connections_description : """The maximum number of
            half-opened incoming connections."""

            bind_retry_interval : 60s
            bind_retry_interval_description : """If binding the server socket
            fails, the server will retry to bind the port after this interval.
            Set to zero (0) to disable bind retries."""

            channel_timeout : 15s
            channel_timeout_description : """The timeout for a channel operation
            such as closing a connection."""

            shutdown_quiet_period : 0s
            shutdown_quiet_period_description : """The interval during the
            server shutdown when the server may continue accepting new
            connections or requests.  If new connections or requests are
            received during the quiet period, the server guarantees to process
            them and the quiet period starts over postponing the shutdown.
            """

            shutdown_timeout : 15s
            shutdown_timeout_description : """The shutdown timeout interval,
            which begins after the expiration of the quiet period.  The timeout
            interval allows tasks that are in progress to complete before the
            server shuts down."""
        }
    }

    auth {
        provider_class : "org.midonet.cluster.auth.MockAuthService"
        provider_class_description : """
        The class of the authentication provider. The MidoNet Cluster includes
        the following authentication providers:
        - org.midonet.cluster.auth.keystone.KeystoneService: authentication
          provider using Keystone identity service
        - org.midonet.cluster.auth.MockAuthService - mock authentication used
          for testing
        """

        admin_role : " "
        admin_role_description : """
        The security role, specifying the set of rights and privileges, used for
        the admin user.
        """

        tenant_admin_role : " "
        tenant_admin_role_description : """
        The security role, specifying the set of rights and privileges, used for
        the admin tenant user.
        """

        tenant_user_role : " "
        tenant_user_role_description : """
        The security role, specifying the set of rights and privileges, used for
        the tenant user.
        """

        keystone {
            version : 3
            version_description : """The version of the identity API."""

            tenant_name : " "
            tenant_name_description : """The name of an administrative tenant or
            project. This tenant or project is used to validate the credentials
            for client requests.
            """

            domain_name : "default"
            domain_name_description : """The name of the administrative domain.
            This domain is used to validate the credentials for client requests.
            """

            user_name : " "
            user_name_description : """The user name for a Keystone admin user.
            This user account is used to validate the credentials for client
            requests. This is optional, and if not specified the configuration
            must provide an administrative token.
            """

            user_password : " "
            user_password_description : """The password for a Keystone admin
            user. This user account is used to validate the credentials for
            client requests. This is optional, and if not specified the
            configuration must provide an administrative token.
            """

            admin_token : " "
            admin_token_description : """
            The token used for administrative access to the Keystone server.
            The admin token is used only if the configuration does not specify
            user name and password credentials.
            """

            protocol : "http"
            protocol_description : """
            The protocol used to access the Keystone server (default is http).
            """

            host : "localhost"
            host_description : """
            The Keystone server host name.
            """

            port : 35357
            port_description : """
            The Keystone server port number.
            """
        }
    }

    translators {
        nat {
            dynamic_port_start: 1024
            dynamic_port_start_description : """
            Start port for the range of available port for for dynamic source
            NAT port allocation. This port must be higher than 0. If the port
            is out of bounds, we default to 1.
            """

            dynamic_port_end: 65535
            dynamic_port_end_description : """
            End port for the range of available port for for dynamic source
            NAT port allocation. The end port must be higher than the start
            port. If not, or the port is out of bounds, we default to 65535.
            """
        }
    }

    loggers {
        root : "INFO"
        root_description : """Root loggers."""

        com.sun.jersey : "WARN"
        org.apache.zookeeper : "INFO"
        org.apache.cassandra : "INFO"
        org.eclipse.jetty : "INFO"
        org.hibernate : "WARN"
        org.opendaylight : "WARN"
        org.reflections : "INFO"

        org.midonet.cluster.root : ${cluster.loggers.root}
        org.midonet.cluster.root_description : """
        Logger for the cluster services."""

        org.midonet.cluster.auth.root : ${cluster.loggers.root}
        org.midonet.cluster.auth.root_description : """
        Logger for generic authentication requests."""
        org.midonet.cluster.auth.keystone : "WARN"
        org.midonet.cluster.auth.keystone_description : """
        Logger for Keystone authentication requests."""

        org.midonet.cluster.services.root : ${cluster.loggers.root}
        org.midonet.cluster.services.root_description : """
        Logger for all cluster services."""

        org.midonet.cluster.services.containers.root : ${cluster.loggers.root}
        org.midonet.cluster.services.containers.root_description : """
        Logger for the Containers service."""

        org.midonet.cluster.services.neutron-importer.root : ${cluster.loggers.root}
        org.midonet.cluster.services.neutron-importer.root_description : """
        Logger for the Neutron Importer service."""
        org.midonet.cluster.services.neutron-importer.importer-deserializer : ${cluster.loggers.root}
        org.midonet.cluster.services.neutron-importer.importer-deserializer_description : """
        Logger for the Neutron Importer service deserializer."""
        org.midonet.cluster.services.neutron-importer.importer-storage-manager : ${cluster.loggers.root}
        org.midonet.cluster.services.neutron-importer.importer-storage-manager_description : """
        Logger for the Neutron Importer service storage manager."""

        org.midonet.cluster.services.heartbeat.root : ${cluster.loggers.root}
        org.midonet.cluster.services.heartbeat.root_description : """
        Logger for the Heartbeat service."""

        org.midonet.cluster.services.rest-api.root : ${cluster.loggers.root}
        org.midonet.cluster.services.rest-api.root_description : """
        Logger for the REST API service."""
        org.midonet.cluster.services.rest-api.jaxrs : ${cluster.loggers.root}
        org.midonet.cluster.services.rest-api.jaxrs_description : """
        Logger for the REST API service JSON serialization."""
        org.midonet.cluster.services.rest-api.neutron : ${cluster.loggers.root}
        org.midonet.cluster.services.rest-api.neutron_description : """
        Logger for the REST API service Neutron requests."""

        org.midonet.cluster.services.state-proxy.root : ${cluster.loggers.root}
        org.midonet.cluster.services.state-proxy.root_description : """
        Logger for the State Proxy service."""
        org.midonet.cluster.services.state-proxy.server : ${cluster.loggers.root}
        org.midonet.cluster.services.state-proxy.server_description : """
        Logger for the State Proxy service server."""

        org.midonet.cluster.services.topology-api.root : ${cluster.loggers.root}
        org.midonet.cluster.services.topology-api.root_description : """
        Logger for the Topology API service."""
        org.midonet.cluster.services.topology-api.aggregator : ${cluster.loggers.root}
        org.midonet.cluster.services.topology-api.aggregator_description : """
        Logger for the Topology API service aggregator."""
        org.midonet.cluster.services.topology-api.session-inventory : ${cluster.loggers.root}
        org.midonet.cluster.services.topology-api.session-inventory_description : """
        Logger for the Topology API service session inventory."""
        org.midonet.cluster.services.topology-api.server-protocol-factory : ${cluster.loggers.root}
        org.midonet.cluster.services.topology-api.server-protocol-factory_description : """
        Logger for the Topology API service server protocol factory."""

        org.midonet.cluster.services.vxgw.root : ${cluster.loggers.root}
        org.midonet.cluster.services.vxgw.root_description : """
        Logger for the VXLAN Gateway service."""
    }

}
