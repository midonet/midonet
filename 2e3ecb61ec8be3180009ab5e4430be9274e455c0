{
  "comments": [
    {
      "key": {
        "uuid": "9ab29df4_754b7fb0",
        "filename": "midolman/src/main/scala/org/midonet/midolman/config/MidolmanConfig.scala",
        "patchSetId": 2
      },
      "lineNbr": 139,
      "author": {
        "id": 1002751
      },
      "writtenOn": "2015-10-28T15:45:39Z",
      "side": 1,
      "message": "Do we want to provide a per-device storage retry policy? The API also uses a retry mechanism albeit not configurable. Should this belong to the backend config (discussion)?",
      "range": {
        "startLine": 139,
        "startChar": 6,
        "endLine": 139,
        "endChar": 25
      },
      "revId": "2e3ecb61ec8be3180009ab5e4430be9274e455c0",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9ab29df4_554e7bc2",
        "filename": "midolman/src/main/scala/org/midonet/midolman/config/MidolmanConfig.scala",
        "patchSetId": 2
      },
      "lineNbr": 148,
      "author": {
        "id": 1002751
      },
      "writtenOn": "2015-10-28T15:45:39Z",
      "side": 1,
      "message": "If these are new config keys, shouldn\u0027t they appear in the schema? If so, the fallback value will be the one from the schema and hence the Try/getOrElse is not needed here.",
      "range": {
        "startLine": 145,
        "startChar": 4,
        "endLine": 148,
        "endChar": 116
      },
      "revId": "2e3ecb61ec8be3180009ab5e4430be9274e455c0",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9ab29df4_15db23ee",
        "filename": "midolman/src/main/scala/org/midonet/midolman/l4lb/HealthMonitor.scala",
        "patchSetId": 2
      },
      "lineNbr": 425,
      "author": {
        "id": 1002751
      },
      "writtenOn": "2015-10-28T15:45:39Z",
      "side": 1,
      "message": "I think you should reschedule this by sending a message to the actor with a delay (an exponential back-off starting from 1 s is too much?), rather than blocking the actor during the retry. In the API we use a similar policy with 3 retries and 0 delay, and that worked fine in most cases. Maybe exponential is okay, but starting from a smaller initial value.",
      "range": {
        "startLine": 402,
        "startChar": 8,
        "endLine": 425,
        "endChar": 23
      },
      "revId": "2e3ecb61ec8be3180009ab5e4430be9274e455c0",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": false
    }
  ]
}