// Copyright 2014 - 2015 Midokura SARL
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MidoNet Agent configuration schema

agent {
    schemaVersion : 21

    bridge {
        mac_port_mapping_expire : 15s
        mac_port_mapping_expire_description : """
        Time interval after which bridges will expire a MAC-port mapping once
        there are no flows that reference it."""
        mac_port_mapping_expire_type : "duration"
    }

    arptable {
        arp_retry_interval = 10s
        arp_retry_interval_description : """Approximate interval between ARP
        request retries by MidoNet virtual routers."""
        arp_retry_interval_type = "duration"

        arp_timeout = 60s
        arp_timeout_description : """Time out for router ARP requests, routers
        will give up resolving an IP address if no ARP replies arrive after this
        period, until there is new traffic that tries to reach that IP address."""
        arp_timeout_type = "duration"

        arp_stale = 60s
        arp_stale_description : """Time period after which a virtual router will
        consider an ARP table entry stale. When stale, entries are still valid
        but routers will try to refresh them if they see traffic using them."""
        arp_stale_type = "duration"

        arp_expiration = 90s
        arp_expiration_description : """Time period after which a virtual router
        will consider an ARP table entry expired, and will delete it from the
        ARP table."""
        arp_expiration_type = "duration"
    }

    router {
        max_bgp_peer_routes : 200
        max_bgp_peer_routes_description : """Maximum number of routes that a
        virtual router will learn from a single BGP peer."""

        bgp_zookeeper_holdtime: 5s
        bgp_zookeeper_holdtime_description: """
Upon a zookeeper disconnection, keep bgp sessions alive during this
time interval before tearing them down, to leave the agent time to
fail over to another zookeeper server without traffic disruption."""
        bgp_zookeeper_holdtime_type: "duration"
    }

    midolman {
        lock_memory : true
        lock_memory_description : """Controls whether the MidoNet agent should
        try to lock itself into RAM. It's strongly recommended to keep this
        setting to true. Otherwise, the agent may become very vulnerable to
        long GC pauses, during which no traffic can be processed, if the system
        starts swapping."""
        lock_memory_type : "bool"

        dhcp_mtu_description : """The MTU served by MidoNet when replying to
        DHCP requests will be the minimum of this value and the tunneling MTU.
        The tunneling MTU is the MTU of the tunneling interface minus the
        tunneling protocol (gre, vxlan) overhead."""
        dhcp_mtu : 1500

        check_flow_expiration_interval : 10s
        check_flow_expiration_interval_description : """The frequency at which
        the MidoNet agent will check and clean up expired flows."""
        check_flow_expiration_interval_type : "duration"

        bgp_keepalive : 60s
        bgp_keepalive_description : """
        Time between transmission of keepalive packets. """
        bgp_keepalive_type : "duration"

        bgp_holdtime : 180s
        bgp_holdtime_description : """
        Maximum tolerated time between keep alive messages."""
        bgp_holdtime_type : "duration"

        bgp_connect_retry : 120s
        bgp_connect_retry_description : """BGP connection retry interval."""
        bgp_connect_retry_type : "duration"

        simulation_threads : 1
        simulation_threads_description : """Number of threads dedicated to
        packet processing."""

        max_pooled_contexts : 1024
        max_pooled_contexts_description : """Maximum number of packet contexts
        to pool per simulation threads. Pooling packet contexts reduces the
        number of allocations needed per simulation."""

        output_channels : 1
        output_channels_description : """Number of datapath output channels."""

        input_channel_threading : "one_to_many"
        input_channel_threading_description : """Threading model for datapath
        input channels. Agents will use one netlink channel per port. Allowed
        values are:

          * one_to_many: use one thread to service all ports.
          * one_to_one: use one thread to service each port."""

        enable_bridge_arp = true
        enable_bridge_arp_description = """If true, virtual bridges will
        use pre-seeded values to reply to ARP requests in their L2 segment."""
    }

    datapath {
        vxlan_vtep_udp_port : 4789
        vxlan_vtep_udp_port_description : """
    This option specifies the value of the udp port used for vxlan tunnelling
    to peer vteps. By default it is set to the standardized vxlan udp port value
    which is 4789."""

        vxlan_overlay_udp_port : 6677
        vxlan_overlay_udp_port_description : """
    This option specifies the value of the udp port used for vxlan tunnelling
    of overlay traffic from midolman hosts to other midolman hosts. The value
    needs to be the same across the cluster. It also needs to be different from
    the vxlan_vtep_udp_port value."""

        vxlan_recirculate_udp_port : 8899
        vxlan_recirculate_udp_port_description : """
    This option specifies the value of the udp port used for vxlan tunnelling
    of traffic that will be recirculated back to the datapath, for encapsulation
    purposes. It also to be different from the other vxlan port numbers."""

        recirc_cidr : "169.254.123.0/24"
        recirc_cidr_description : """
    This option specifies a /24 subnet from which we'll allocate IP addresses
    for in-host circulation of packets, for encapsulation and decapsulation
    purposes. Other interfaces on the host must not use addresses in this range."""

        max_flow_count : 20000
        max_flow_count_description : """
    Maximum number of flows a given datapath will be able to contain."""

        send_buffer_pool_max_size : 4096
        send_buffer_pool_max_size_description : """
    Midolman uses a pool of reusable buffers to send requests to the
    datapath. The options below tune the pool's size and that of its
    buffers. One pool is created for each output channel, the settings
    defined here will apply to each of those pools.
    max_size: maximum number of buffers to hold in the pool. When the
              pool is empty (all buffers are in use) and has reached
              its maximum size, temporary buffers will be allocated.
    """

        send_buffer_pool_initial_size : 2048
        send_buffer_pool_initial_size_description : """
    Initial number of buffers to allocate in the datapath send buffer pool."""


        send_buffer_pool_buf_size_kb = 4
        send_buffer_pool_buf_size_kb_description : """
    Size of each buffer in the datapath send buffer pool, in kb. Maximum total
    pool size would thus be: max_size * buf_size_kb. Beware that the buffer size
    puts a limit on the packet size that Midolman can send. In a network
    jumbo frames, adjust the size so that one buffer will accomodate a whole
    frame plus enough room for the flow's actions.

    Recommended values are 4 for underlays with a standard 1500 MTU and 10
    in underlays that use jumbo frames."""

        htb_description = """
    Midolman limits the amount of packets in flight in the system at any
    given time. This prevents its internal queues from growing infinitely.
    Additionally, midolman ensures that its processing capacity is shared
    fairly among ports connected to the datapath. This, for example,
    would prevent a single VM from setting up new flows at a rate that
    would starve other VMs in the system.

    This behaviour is achieved by routing packets that miss the datapath
    flow table and rise to userspace through a Hierarchical Token Bucket.
    This HTB is set up in such a way such that tunnel ports will get 50%
    of the resources, and the remaining 50% is shared fairly among all
    other ports (typically, VMs).

    The rate at which the buckets are refilled is automatic and dynamic.
    However the size of the buckets at each stage of the HTB can be tuned
    through the settings below, increasing a bucket size will increase the
    burstiness at which traffic can be queued before new tokens become
    available.

    Bucket size is measured in packets.

    global_incoming_burst_capacity: size of the HTB root bucket
    tunnel_incoming_burst_capacity: bucket size for tunnel ports (GRE, VxLAN)
    vm_incoming_burst_capacity: bucket size for VM ports
    vtep_incoming_burst_capacity: bucket size for VTEP (VxLAN) ports.
    """

        global_incoming_burst_capacity : 256
        global_incoming_burst_capacity_description : ${agent.datapath.htb_description}

        tunnel_incoming_burst_capacity : 128
        tunnel_incoming_burst_capacity_description : ${agent.datapath.htb_description}

        vm_incoming_burst_capacity : 32
        vm_incoming_burst_capacity_description : ${agent.datapath.htb_description}

        vtep_incoming_burst_capacity : 128
        vtep_incoming_burst_capacity_description : ${agent.datapath.htb_description}

        control_packet_tos : 184
        control_packet_tos_description : """ """
    }

    haproxy_health_monitor {
        health_monitor_enable : true
        health_monitor_enable_description : """
    Health monitor is enabled by default. Please change the following value to
    false to disable it.
    """
        namespace_cleanup = true

        haproxy_file_loc = "/etc/midolman/l4lb/"
    }

    loggers {
        root : "INFO"

        org.apache.zookeeper : "INFO"
        org.apache.cassandra : "INFO"
        me.prettyprint.cassandra : "INFO"
        org.eclipse.jetty : "INFO"
        com.datastax : "INFO"

        org.midonet.packets.default.packet-processor : ${agent.loggers.root}
        org.midonet.packets.default.packet-processor_description : """
    Adjust this level to set the logging used for all packets processed"""

        org.midonet.packet-worker : ${agent.loggers.root}
        org.midonet.packet-worker_description : """
    logger for packet processing worker threads, when outside the context of a packet"""

        org.midonet.devices.arp-table : ${agent.loggers.root}
        org.midonet.devices.arp-table_description : """
    catch-all logger for arp table messages"""

        // arp table messages for a specific router
        // org.midonet.devices.arp-table.arp-table-THE_ROUTER_UUID : "INFO"

        org.midonet.routing.bgp : ${agent.loggers.root}
        org.midonet.flow-management : ${agent.loggers.root}
        org.midonet.datapath-control : ${agent.loggers.root}
        org.midonet.devices.devices-service : ${agent.loggers.root}
        org.midonet.devices.underlay : ${agent.loggers.root}
        org.midonet.state.table : ${agent.loggers.root}
        org.midonet.state.replication : ${agent.loggers.root}

        org.midonet.devices.bridge : ${agent.loggers.root}
        org.midonet.devices.bridge_description : """
    logger for all bridges and their mac learning tables"""

        // particular bridge and its mac learning tables
        // org.midonet.devices.bridge.bridge-THE_BRIDGE_UUID : "INFO"

        // communications with the datapath
        org.midonet.netlink : ${agent.loggers.root}
        org.midonet.io.select-loop : ${agent.loggers.root}
        org.midonet.io.htb : ${agent.loggers.root}

        org.midonet.containers.root : ${agent.loggers.root}
        org.midonet.containers.root_description : """
    Logger for the container service."""
        org.midonet.containers.ipsec.root : ${agent.loggers.root}
        org.midonet.containers.ipsec.root_description : """
    Logger for the IPSec container."""
        org.midonet.containers.ipsec.ipsec-pluto : ${agent.loggers.root}
        org.midonet.containers.ipsec.ipsec-pluto_description : """
    Logger for the IPSec pluto process running inside the IPSec container."""
        org.midonet.services.root : ${agent.loggers.root}
        org.midonet.services.root_description : """
    Logger for the Midonet Agent Services (a.k.a Agent Minions) subsystem."""
        org.midonet.services.binding-api : ${agent.loggers.root}
        org.midonet.services.binding-api_description : """
    Logger for the binding API agent minion."""
        org.midonet.services.l4lb.root : ${agent.loggers.root}
        org.midonet.services.l4lb.root_description : """
    Logger for the load balancer service."""
    }

    cluster {
        enabled : false
        enabled_description : """
Used by the mm-ctl tool. When enabled, it will try to communicate
via the API server. Otherwise, it will use the cluster database."""

        tasks_db_connection : " "
        tasks_db_connection_description : """
Used by the mm-ctl tool. This is the connection string used
to connect to the cluster database where the task entries are located."""
    }

    flow_history {
        enabled: false
        enabled_description: """
Whether flow summaries will be recorded for each flow simulation. """

        encoding: binary
        encoding_type: "enum[none, json, binary]"
        encoding_description: """
Encoding type used to send flow summaries.
The remote endpoint must be configured to receive messages in this format"""

        endpoint_service: "clio"
        endpoint_service_description: """
Name of the endpoint (as registered in service discovery) that is responsible
for receiving flow history records."""

        queue_size: "128"
        queue_size_description: """
Maximum size of the recording queue where flow records await to be sent to
the endpoint. Should be a power of 2 (next closest power of 2 is chosen
otherwise)."""
    }

    openstack {
        metadata {
            enabled: false
            enabled_description: """
Whether instance metadata service is enabled."""
            nova_metadata_url: "http://localhost:8775"
            nova_metadata_url_description: """
URL of Nova Metadata API."""
            shared_secret: ""
            shared_secret_description: """
Shared secret used to comminucate with Nova Metadata API."""
        }
    }

    rule_logging {
        compress: true
        compress_description: "Compress old rule logs with gzip after rotation."

        log_file_name: "rule-binlog.rlg"
        log_file_name_description: "Name of rule log file."

        log_directory: ""
        log_directory_description: """
Directory to write rule logs to. Defaults to the midolman log directory."""

        max_files: 14
        max_files_description: """
Maximum number of rotated rule log files to retain, not counting the current
file. If this many files already exist, the oldest will be deleted on the next
rotation. With the default setting of rotation_frequency = "1 day" and
max_files = 14, rule logs will be retained for two weeks."""

        rotation_frequency: "1 day"
        rotation_frequency_description: """
Frequency with which rule logs are rotated. May be expressed in time ("1 day",
"8 hours", "90 minutes", etc.) or size ("500MB", "10GB", etc.)"""
    }

    containers {
        enabled : true
        enabled_description : """
Whether this agent instance can run service containers."""

        timeout : 30s
        timeout_description : """
Timeout for a container operation to complete."""
        timeout_type : "duration"

        shutdown_grace_time : 30s
        shutdown_grace_time_description : """
Time interval to wait for all service containers to stop gracefully when
the agent shuts down."""
        shutdown_grace_time_type : "duration"

        thread_count : 4
        thread_count_description : """
The number of threads that manage the containers executing at this agent.  This
determines the number of containers that can be changed in parallel.  Once
created a container is bound to the same thread on which it was created."""

        log_directory : "containers"
        log_directory_description : """
The name of the container log directory. The MidoNet agent will write to this
directory the records of the existing containers. The directory will be created
on the same path as the agent log."""

        ipsec {
            logging_enabled : true
            logging_enabled_description : """
Whether the IPSec container relays the log message from the IPSec process
running inside the container to the agent log."""

            logging_poll_interval : 250ms
            logging_poll_interval_description : """
Polling interval for the IPSec process log."""

            logging_timeout : 3s
            logging_timeout_description : """
Timeout for an I/O operation on the IPSec process log file."""
            logging_timeout_type : "duration"

            status_update_interval : 5s
            status_update_interval_description : """
Time interval for reading the status of the IPSec process running inside the
container and reporting the status to the container service.  The container
service will update the status in NSDB."""
            status_update_interval_type : "duration"
        }
    }

    minions {
        executors {
            max_thread_pool_size: 8
            max_thread_pool_size_description: """ The maximum number of threads
            allocated in the services node thread pool.  The cluster node will
            allocate a number of threads in the agent thread pool equal to the
            number of available processors, but no more than this maximum. """

            thread_pool_shutdown_timeout: 10s
            thread_pool_shutdown_timeout_description: """ The timeout interval
            for shutting down the cluster thread pool."""
            thread_pool_shutdown_timeout_type: "duration"

            thread_pool_name: "agent-services-pool"
            thread_pool_name_description: """ The name of the thread pool used
            internally. DO NOT CHANGE."""
        }

        flow_state {
            enabled : true
            enabled_description : """ Whether the FlowState minion runs in this
            Midonet Agent node. This service receives flow state information
            from its parent process and stores it in Cassandra."""

            legacy_push_state : false
            legacy_push_state_description : """ Whether the FlowState minion
            will save incoming flow state messages Cassandra."""

            local_push_state : true
            local_push_state_description : """ Whether the FlowState minion
            will save incoming flow state messages to local storage on the
            MidoNet Agent."""

            port : 6688
            port_description : """ The value of the UDP and TCP ports used to
            listen for incoming flow state messages from the parent Agent
            process through the loopback interface, and flow state transfer
            requests."""

            connection_timeout : 2s
            connection_timeout_description : """ Timeout for TCP requests during
            flow state exchanges."""

            block_size : 262144
            block_size_description : """
            The size in bytes of the compressed block for the flow state
            storage. Changing this has an impact on the amount of memory used
            as well as the compression ratio achieved by the snappy algorithm.
            Setting a higher value implies an increased memory usage and
            potentially a higher compression ratio. Defaults to 256 KB."""

            blocks_per_port : 512
            blocks_per_port_description : """
            The number of allowed blocks of compressed flow state per virtual
            port. By default, it will use up to 128 MB (512 blocks of 256 KB)
            per virtual port. It does not pre-allocate blocks so disk space will
            not be used unless it's filled with data. With this space, we can
            hold around 500k messages at a rate of 4k flows per second for
            a given port (not considering compression)."""

            expiration_time : 120s
            expiration_time_description : """
            How long should we keep flow state stored. Flow state entries older
            than this period of time will be eligible for removal."""

            expiration_delay : 30s
            expiration_delay_description : """
            The delay between consecutive flow state invalidation tasks that
            remove and clear the blocks that are older than the expiration time.
            This task only marks the block headers as invalid if they are
            expired so the overhead is minimum."""

            clean_unused_files_delay : 12h
            clean_unused_files_delay_description : """
            The delay between consecutive runs of the flow state file cleaner
            task. This is a background task that looks into the current list
            of flow state files and removes those not being used (written to
            or reading from). This is a background housekeeping activity to
            prevent storage from being used needlessly."""

            log_directory : "flowstate"
            log_directory_description : """
            The name of the flow state log directory. The MidoNet Agent will
            write to this directory the records of the current flow state
            associated to the ports bound to this agent. This directory will be
            created in /var/db/midolman by default."""
        }

        binding_api {
            enabled : true
            enabled_description : """Whether the BindingApi minion runs in
            this Midonet Agent node. This service processes mm-ctl bind/unbind
            requests."""

            unix_socket : "/var/run/midolman/midolman.sock"
            unix_socket_description : """The unix domain socket path on which the
            BindingApi minion listens requests.  DO NOT change this unless
            you are sure about implications.  The mm-ctl command knows about
            this path."""
        }
    }
}
