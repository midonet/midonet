// Copyright 2014 - 2015 Midokura SARL
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MidoNet Agent configuration schema

agent {
    schemaVersion : 6

    bridge {
        mac_port_mapping_expire : 15s
        mac_port_mapping_expire_description : """
        Time interval after which bridges will expire a MAC-port mapping once
        there are no flows that reference it."""
        mac_port_mapping_expire_type : "duration"
    }

    arptable {
        arp_retry_interval = 10s
        arp_retry_interval_description : """Approximate interval between ARP
        request retries by MidoNet virtual routers."""
        arp_retry_interval_type = "duration"

        arp_timeout = 60s
        arp_timeout_description : """Time out for router ARP requests, routers
        will give up resolving an IP address if no ARP replies arrive after this
        period, until there is new traffic that tries to reach that IP address."""
        arp_timeout_type = "duration"

        arp_stale = 1800s
        arp_stale_description : """Time period after which a virtual router will
        consider an ARP table entry stale. When stale, entries are still valid
        but routers will try to refresh them if they see traffic using them."""
        arp_stale_type = "duration"

        arp_expiration = 3600s
        arp_expiration_description : """Time period after which a virtual router
        will consider an ARP table entry expired, and will delete it from the
        ARP table."""
        arp_expiration_type = "duration"
    }

    router {
        max_bgp_peer_routes : 200
        max_bgp_peer_routes_description : """Maximum number of routes that a
        virtual router will learn from a single BGP peer."""

        bgp_zookeeper_holdtime: 5s
        bgp_zookeeper_holdtime_description: """
Upon a zookeeper disconnection, keep bgp sessions alive during this
time interval before tearing them down, to leave the agent time to
fail over to another zookeeper server without traffic disruption."""
        bgp_zookeeper_holdtime_type: "duration"
    }

    midolman {
        lock_memory : true
        lock_memory_description : """Controls whether the MidoNet agent should
        try to lock itself into RAM. It's strongly recommended to keep this
        setting to true. Otherwise, the agent may become very vulnerable to
        long GC pauses, during which no traffic can be processed, if the system
        starts swapping."""
        lock_memory_type : "bool"

        dhcp_mtu_description : """The MTU served by MidoNet when replying to
        DHCP requests will be the minimum of this value and the tunneling MTU.
        The tunneling MTU is the MTU of the tunneling interface minus the
        tunneling protocol (gre, vxlan) overhead."""
        dhcp_mtu : 1500

        check_flow_expiration_interval : 10s
        check_flow_expiration_interval_description : """The frequency at which
        the MidoNet agent will check and clean up expired flows."""
        check_flow_expiration_interval_type : "duration"

        bgp_keepalive : 60s
        bgp_keepalive_description : """
        Time between transmission of keepalive packets. """
        bgp_keepalive_type : "duration"

        bgp_holdtime : 180s
        bgp_holdtime_description : """
        Maximum tolerated time between keep alive messages."""
        bgp_holdtime_type : "duration"

        bgp_connect_retry : 120s
        bgp_connect_retry_description : """BGP connection retry interval."""
        bgp_connect_retry_type : "duration"

        simulation_threads : 1
        simulation_threads_description : """Number of threads dedicated to
        packet processing."""

        output_channels : 1
        output_channels_description : """Number of datapath output channels."""

        input_channel_threading : "one_to_many"
        input_channel_threading_description : """Threading model for datapath
        input channels. Agents will use one netlink channel per port. Allowed
        values are:

          * one_to_many: use one thread to service all ports.
          * one_to_one: use one thread to service each port."""

        enable_bridge_arp = true
        enable_bridge_arp_description = """If true, virtual bridges will
        use pre-seeded values to reply to ARP requests in their L2 segment."""
    }

    datapath {
        vxlan_vtep_udp_port : 4789
        vxlan_vtep_udp_port_description : """
    This option specifies the value of the udp port used for vxlan tunnelling
    to peer vteps. By default it is set to the standardized vxlan udp port value
    which is 4789."""

        vxlan_recirculate_udp_port : 6676
        vxlan_recirculate_udp_port_description : """
    This option specifies the value of the udp port used for adding or removing
    a full vxlan header (including udp, ip, and ethernet headers) and
    recirculating the packet to the datapath. This value does not need to be
    uniform across the cluster; however, it does need to be different from that
    of the other vxlan udp ports on the same host."""

        vxlan_overlay_udp_port : 6677
        vxlan_overlay_udp_port_description : """
    This option specifies the value of the udp port used for vxlan tunnelling
    of overlay traffic from midolman hosts to other midolman hosts. The value
    needs to be the same across the cluster. It also needs to be different from
    the vxlan_vtep_udp_port value."""

        max_flow_count : 20000
        max_flow_count_description : """
    Maximum number of flows a given datapath will be able to contain."""

        send_buffer_pool_max_size : 4096
        send_buffer_pool_max_size_description : """
    Midolman uses a pool of reusable buffers to send requests to the
    datapath. The options below tune the pool's size and that of its
    buffers. One pool is created for each output channel, the settings
    defined here will apply to each of those pools.
    max_size: maximum number of buffers to hold in the pool. When the
              pool is empty (all buffers are in use) and has reached
              its maximum size, temporary buffers will be allocated.
    """

        send_buffer_pool_initial_size : 2048
        send_buffer_pool_initial_size_description : """
    Initial number of buffers to allocate in the datapath send buffer pool."""


        send_buffer_pool_buf_size_kb = 4
        send_buffer_pool_buf_size_kb_description : """
    Size of each buffer in the datapath send buffer pool, in kb. Maximum total
    pool size would thus be: max_size * buf_size_kb. Beware that the buffer size
    puts a limit on the packet size that Midolman can send. In a network
    jumbo frames, adjust the size so that one buffer will accomodate a whole
    frame plus enough room for the flow's actions.

    Recommended values are 4 for underlays with a standard 1500 MTU and 10
    in underlays that use jumbo frames."""

        htb_description = """
    Midolman limits the amount of packets in flight in the system at any
    given time. This prevents its internal queues from growing infinitely.
    Additionally, midolman ensures that its processing capacity is shared
    fairly among ports connected to the datapath. This, for example,
    would prevent a single VM from setting up new flows at a rate that
    would starve other VMs in the system.

    This behaviour is achieved by routing packets that miss the datapath
    flow table and rise to userspace through a Hierarchical Token Bucket.
    This HTB is set up in such a way such that tunnel ports will get 50%
    of the resources, and the remaining 50% is shared fairly among all
    other ports (typically, VMs).

    The rate at which the buckets are refilled is automatic and dynamic.
    However the size of the buckets at each stage of the HTB can be tuned
    through the settings below, increasing a bucket size will increase the
    burstiness at which traffic can be queued before new tokens become
    available.

    Bucket size is measured in packets.

    global_incoming_burst_capacity: size of the HTB root bucket
    tunnel_incoming_burst_capacity: bucket size for tunnel ports (GRE, VxLAN)
    vm_incoming_burst_capacity: bucket size for VM ports
    vtep_incoming_burst_capacity: bucket size for VTEP (VxLAN) ports.
    """

        global_incoming_burst_capacity : 128
        global_incoming_burst_capacity_description : ${agent.datapath.htb_description}

        tunnel_incoming_burst_capacity : 64
        tunnel_incoming_burst_capacity_description : ${agent.datapath.htb_description}

        vm_incoming_burst_capacity : 16
        vm_incoming_burst_capacity_description : ${agent.datapath.htb_description}

        vtep_incoming_burst_capacity : 64
        vtep_incoming_burst_capacity_description : ${agent.datapath.htb_description}

        control_packet_tos : 184
        control_packet_tos_description : """ """
    }

    haproxy_health_monitor {
        health_monitor_enable : false
        health_monitor_enable_description : """
    Health monitor is disabled by default. Please change the following value to
    true to activate it.
    """
        namespace_cleanup = false

        haproxy_file_loc = "/etc/midolman/l4lb/"
    }

    loggers {
        root : "INFO"

        org.apache.zookeeper : "INFO"
        org.apache.cassandra : "INFO"
        me.prettyprint.cassandra : "INFO"
        org.eclipse.jetty : "INFO"

        org.midonet.packets.default.packet-processor : ${agent.loggers.root}
        org.midonet.packets.default.packet-processor_description : """
    Adjust this level to set the logging used for all packets processed"""

        org.midonet.packet-worker : ${agent.loggers.root}
        org.midonet.packet-worker_description : """
    logger for packet processing worker threads, when outside the context of a packet"""

        org.midonet.devices.arp-table : ${agent.loggers.root}
        org.midonet.devices.arp-table_description : """
    catch-all logger for arp table messages"""

        // arp table messages for a specific router
        // org.midonet.devices.arp-table.arp-table-THE_ROUTER_UUID : "INFO"

        org.midonet.routing.bgp : ${agent.loggers.root}
        org.midonet.flow-management : ${agent.loggers.root}
        org.midonet.datapath-control : ${agent.loggers.root}
        org.midonet.devices.devices-service : ${agent.loggers.root}
        org.midonet.devices.underlay : ${agent.loggers.root}
        org.midonet.state.table : ${agent.loggers.root}
        org.midonet.state.replication : ${agent.loggers.root}

        org.midonet.devices.bridge : ${agent.loggers.root}
        org.midonet.devices.bridge_description : """
    logger for all bridges and their mac learning tables"""

        // particular bridge and its mac learning tables
        // org.midonet.devices.bridge.bridge-THE_BRIDGE_UUID : "INFO"

        // communications with the datapath
        org.midonet.netlink : ${agent.loggers.root}
        org.midonet.io.select-loop : ${agent.loggers.root}
        org.midonet.io.htb : ${agent.loggers.root}
    }

    cluster {
        enabled : false
        enabled_description : """
Used by the mm-ctl tool. When enabled, it will try to communicate
via the API server. Otherwise, it will use the cluster database."""

        tasks_db_connection : " "
        tasks_db_connection_description : """
Used by the mm-ctl tool. This is the connection string used
to connect to the cluster database where the task entries are located."""
    }

    flow_history {
        enabled: false
        enabled_description: """
Whether flow summaries will be recorded for each flow simulation. """

        encoding: none
        encoding_type: "enum[none, json, binary]"
        encoding_description: """
Encoding type used to send flow summaries.
The remote endpoint must be configured to receive messages in this format"""

        udp_endpoint: "localhost:5000"
        udp_endpoint_description: """
Endpoint to which flow summaries will be sent over UDP.
The format is <host or ip>:<port>."""
    }
}
